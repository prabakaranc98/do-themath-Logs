# do-the-math — Logs

A tiny, stubborn commitment to mathematical fluency. This repo tracks a daily loop of **Read → Exercise → Code** across the math that powers AI/ML/DS: probability, calculus/analysis, linear algebra, optimization, information theory, and the math in my current courses—**causal inference**, **probabilistic machine learning**, and **reinforcement learning algorithms**.

## Week 1 - Oct 2025 
----

#### 10/01
  - excercise 1: 2.4 of Causal Inference book - link to Proof : TBA
#### 10/2 
  - worked on derivation of MDPs and Black well optimality.






















## Why this exists

Surface-level projects are easy to start and easy to fake. Real capability comes from proofs, derivations, counterexamples, and the habit of turning ideas into minimal, working code. The aim here isn’t volume or novelty; it’s **clarity** and **control**—to understand definitions precisely, to manipulate them confidently, and to instantiate them in code without crutches.

## What this is

- A **daily practice** of 5–10 small, essential, graduate-level exercises.
- Drawn from **primary sources** (course texts, notes, official problem sets).
- Anchored in three verbs:
  - **Read:** just enough to state definitions, lemmas, and assumptions cleanly.
  - **Exercise:** solve tightly scoped problems; write crisp arguments.
  - **Code:** a tiny implementation or check that makes the math concrete.

The entries are short by design. The work is not.

## How a day feels (narrative, not a template)

Skim a section until the objects and assumptions are explicit. Pick 1–2 themes (e.g., contraction mappings; MLE for exponential families). Solve several problems that probe the edges—existence/uniqueness, stability, counterexamples. Then ship a minimal program (30–60 lines) that **verifies a claim** or **constructs a counterexample**: value iteration contracting in the sup-norm; QR from first principles; a likelihood that exposes an identifiability pitfall. Close with one sentence: *what changed in my mental model today?*

## Boundaries

- **Math-first.** No sprawling apps, no benchmark theatre.
- **Small units.** Depth over breadth; proofs over patterns.
- **Source-faithful.** Prefer original derivations to secondary summaries.
- **Evidence.** Every idea leaves a trace: solved problems and a runnable check.
- **Compounding.** Revisit fragile spots until they’re boring.

## What “done” means each day

1. I can **state** the object (spaces, norms, σ-algebras, kernels, etc.).
2. I can **prove** or reconstruct the key step without peeking.
3. I can **instantiate** it in code and see it behave as theory predicts (or fail for a good reason).

## North star

To make the math of inference, learning, and decision-making **operational**: the ability to move from definition → lemma → algorithm with calm precision. If I can’t derive it or implement a toy that exhibits it, I don’t yet know it.

---
*Read. Exercise. Code. Repeat.* 
